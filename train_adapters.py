# helios/train_adapters.py (æœ€ç»ˆå®Œæ•´ç‰ˆ)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR
from transformers import AutoTokenizer, AutoModelForCausalLM
import json
from tqdm import tqdm
import os
from typing import Dict, List, Any

from adapters.adapter import SemanticAdapter
from configs.config import BASE_MODEL_NAME, HIDDEN_SIZE, BOTTLENECK_DIM, TARGET_COMM_LAYER, DEVICE

# --- 1. åˆå§‹åŒ–æ¨¡åž‹ã€åˆ†è¯å™¨ ---

print("Loading base model and tokenizer for training...")
# ä¸ºäº†æ€§èƒ½ï¼Œæˆ‘ä»¬ä¾ç„¶ä½¿ç”¨åŠç²¾åº¦ï¼Œä¹‹å‰å·²ç»éªŒè¯è¿‡é€Ÿåº¦æå‡å·¨å¤§
dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16
tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)
base_model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL_NAME,
    torch_dtype=dtype
).to(DEVICE)
base_model.eval()
print("Freezing base model parameters...")
for param in base_model.parameters():
    param.requires_grad = False

# --- 2. æ ¸å¿ƒè¾…åŠ©å‡½æ•° (é‡å¤§ä¿®æ­£) ---

@torch.no_grad()
def get_semantic_vector(text: str) -> torch.Tensor:
    """å°†ã€ç®€æ´ã€‘çš„ç›®æ ‡æ–‡æœ¬ç¼–ç æˆå…¶æ ¸å¿ƒè¯­ä¹‰ã€å•ä¸€å¹³å‡å‘é‡ã€‘ã€‚"""
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(DEVICE)
    outputs = base_model(**inputs, output_hidden_states=True)
    hidden_state = outputs.hidden_states[TARGET_COMM_LAYER]
    mask = inputs.attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()
    semantic_vector = torch.sum(hidden_state * mask, dim=1) / mask.sum(dim=1)
    return semantic_vector

@torch.no_grad()
def get_simulated_thought_sequence(prompt: str, max_new_tokens: int = 75) -> torch.Tensor:
    """
    é€šè¿‡æ¨¡æ‹Ÿä¸€ä¸ªAgentå®Œæ•´çš„æ€è€ƒè¿‡ç¨‹ï¼ŒèŽ·å–å…¶ã€æœ€åŽä¸€å±‚å®Œæ•´çš„éšè—çŠ¶æ€åºåˆ—ã€‘ã€‚
    è¿™æ˜¯æœ€ç¬¦åˆæ¨¡åž‹å·¥ä½œåŽŸç†çš„â€œæ€æƒ³â€è¡¨ç¤ºã€‚
    """
    inputs = tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True).to(DEVICE)
    # æ­¥éª¤1: ä»…ç”¨generateèŽ·å–ç”Ÿæˆçš„token ids
    generated_ids = base_model.generate(
        inputs.input_ids,
        attention_mask=inputs.attention_mask,
        max_new_tokens=max_new_tokens,
        eos_token_id=tokenizer.eos_token_id,
        pad_token_id=tokenizer.eos_token_id,
        do_sample=False
    )
    # æ­¥éª¤2: å°†è¾“å…¥å’Œè¾“å‡ºçš„idsæ‹¼æŽ¥ï¼Œå¾—åˆ°å®Œæ•´çš„åºåˆ—
    full_sequence_ids = torch.cat([inputs.input_ids, generated_ids[:, inputs.input_ids.shape[1]:]], dim=1)
    
    # æ­¥éª¤3: å¯¹å®Œæ•´åºåˆ—è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œä»¥èŽ·å–æœ€å¹²å‡€ã€æœ€å®Œæ•´çš„éšè—çŠ¶æ€
    outputs = base_model(full_sequence_ids, output_hidden_states=True)
    # è¿”å›žæœ€åŽä¸€å±‚çš„å®Œæ•´éšè—çŠ¶æ€åºåˆ—ï¼Œå½¢çŠ¶ä¸º [batch_size, seq_len, hidden_size]
    final_hidden_sequence = outputs.hidden_states[-1]
    return final_hidden_sequence

# --- 3. æ ¸å¿ƒè®­ç»ƒé€»è¾‘å°è£… (é‡å¤§ä¿®æ­£) ---

def train_single_adapter(
    adapter: SemanticAdapter, 
    optimizer: optim.Optimizer,
    scheduler: CosineAnnealingLR,
    scenarios: List[Dict[str, Any]], 
    source_key: str, 
    target_key: str, 
    epochs: int,
    adapter_name: str
):
    """ä¸€ä¸ªé€šç”¨çš„å‡½æ•°ï¼Œç”¨äºŽè®­ç»ƒå•ä¸ªé€‚é…å™¨ã€‚"""
    print(f"\n--- Training Adapter: {adapter_name} ({source_key} -> {target_key}) ---")
    adapter.train()
    cosine_loss_fn = nn.CosineEmbeddingLoss()
    epoch_progress_bar = tqdm(range(epochs), desc=f"Adapter: {adapter_name}")
    last_avg_loss = 0.0

    for epoch in epoch_progress_bar:
        total_loss = 0
        for scenario in scenarios:
            optimizer.zero_grad()
            source_text = scenario.get(source_key)
            target_text = scenario.get(target_key)
            if not source_text or not target_text: continue

            source_agent_prompt = f"You are a financial analyst. Your task is to process the following information and form a conclusion. Information: '{source_text}'"
            
            # --- æ ¸å¿ƒä¿®æ”¹ ---
            # 1. æºâ€œæ€æƒ³â€çŽ°åœ¨æ˜¯ä¸€ä¸ªå®Œæ•´çš„åºåˆ—
            h_source_sequence = get_simulated_thought_sequence(source_agent_prompt)
            
            # 2. é€‚é…å™¨ç¿»è¯‘æ•´ä¸ªåºåˆ—
            h_predicted_sequence = adapter(h_source_sequence)
            
            # 3. æˆ‘ä»¬å¸Œæœ›ç¿»è¯‘åŽçš„åºåˆ—ï¼Œå…¶ã€å¹³å‡æ€æƒ³ã€‘ä¸Žæˆ‘ä»¬çš„ç›®æ ‡ä¸€è‡´
            h_predicted_mean_vector = h_predicted_sequence.mean(dim=1)
            
            # 4. ç›®æ ‡æ€æƒ³ä¾ç„¶æ˜¯ä¸€ä¸ªç®€æ´çš„å•ä¸€å‘é‡
            h_target_mean_vector = get_semantic_vector(target_text)
            
            y = torch.ones(h_source_sequence.shape[0]).to(DEVICE)
            loss = cosine_loss_fn(h_predicted_mean_vector, h_target_mean_vector, y)
            
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        scheduler.step()
        last_avg_loss = total_loss / len(scenarios) if scenarios else 0
        epoch_progress_bar.set_postfix(avg_loss=f"{last_avg_loss:.6f}", lr=f"{scheduler.get_last_lr()[0]:.1e}")
    
    print(f"Adapter '{adapter_name}' training finished. Final Avg Loss: {last_avg_loss:.6f}")

# --- 4. ä¸»è®­ç»ƒåè°ƒå‡½æ•° (æ— éœ€ä¿®æ”¹) ---
def run_training_pipeline():
    # ... (æ­¤å‡½æ•°å†…å®¹å®Œå…¨ä¸å˜ï¼Œç›´æŽ¥å¤ç”¨å³å¯)
    print("ðŸš€ Initializing training pipeline...")

    adapters_to_train = {
        "analyst_to_trader": SemanticAdapter(HIDDEN_SIZE, BOTTLENECK_DIM).to(DEVICE),
        "bull_to_bear": SemanticAdapter(HIDDEN_SIZE, BOTTLENECK_DIM).to(DEVICE),
        "bear_to_bull": SemanticAdapter(HIDDEN_SIZE, BOTTLENECK_DIM).to(DEVICE),
        "trader_to_risk": SemanticAdapter(HIDDEN_SIZE, BOTTLENECK_DIM).to(DEVICE)
    }
    print(f"Adapters to train: {list(adapters_to_train.keys())}")

    trainable_params = [p for adapter in adapters_to_train.values() for p in adapter.parameters()]
    optimizer = optim.AdamW(trainable_params, lr=5e-4, weight_decay=0.01)
    
    total_epochs = 80 
    scheduler = CosineAnnealingLR(optimizer, T_max=total_epochs, eta_min=1e-6)

    # ä»»åŠ¡1
    try:
        with open("data/analyst_to_trader_scenarios.jsonl", "r") as f:
            scenarios_at = [json.loads(line) for line in f]
        train_single_adapter(
            adapters_to_train['analyst_to_trader'], 
            optimizer, scheduler, scenarios_at, 
            source_key='analyst_input', 
            target_key='ideal_trader_starting_thought',
            epochs=20, adapter_name="analyst_to_trader"
        )
    except FileNotFoundError:
        print("WARNING: 'data/analyst_to_trader_scenarios.jsonl' not found. Skipping.")

    # ä»»åŠ¡2
    try:
        with open("data/debate_scenarios.jsonl", "r") as f:
            scenarios_db = [json.loads(line) for line in f]
        train_single_adapter(
            adapters_to_train['bull_to_bear'],
            optimizer, scheduler, scenarios_db,
            source_key='attacker_argument',
            target_key='ideal_rebuttal_thought',
            epochs=20, adapter_name="bull_to_bear"
        )
    except FileNotFoundError:
        print("WARNING: 'data/debate_scenarios.jsonl' not found. Skipping.")
        
    # ä»»åŠ¡3
    try:
        with open("data/debate_scenarios_rebuttal.jsonl", "r") as f:
             scenarios_db_rebuttal = [json.loads(line) for line in f]
        train_single_adapter(
            adapters_to_train['bear_to_bull'],
            optimizer, scheduler, scenarios_db_rebuttal,
            source_key='rebuttal_argument',
            target_key='ideal_counter_attack_thought',
            epochs=20, adapter_name="bear_to_bull"
        )
    except FileNotFoundError:
        print("WARNING: 'data/debate_scenarios_rebuttal.jsonl' not found. Skipping.")

    # ä»»åŠ¡4
    try:
        with open("data/trader_to_risk_scenarios.jsonl", "r") as f:
             scenarios_tr = [json.loads(line) for line in f]
        train_single_adapter(
            adapters_to_train['trader_to_risk'],
            optimizer, scheduler, scenarios_tr,
            source_key='trader_plan_text',
            target_key='ideal_risk_manager_thought',
            epochs=20, adapter_name="trader_to_risk"
        )
    except FileNotFoundError:
        print("WARNING: 'data/trader_to_risk_scenarios.jsonl' not found. Skipping.")

    print("\nâœ… All training tasks finished. Saving adapter weights...")
    output_dir = "adapters"
    os.makedirs(output_dir, exist_ok=True)
    
    for name, adapter in adapters_to_train.items():
        if any(p.grad is not None for p in adapter.parameters()):
            save_path = os.path.join(output_dir, f"{name}_adapter.pth")
            torch.save(adapter.state_dict(), save_path)
            print(f"  -> Saved '{name}' adapter to '{save_path}'")
            
    print("Adapters saved successfully!")


if __name__ == "__main__":
    run_training_pipeline()